#!/usr/bin/env python

# Copyright (c) 2015
#
# All rights reserved.
#
# This file is distributed under the Clear BSD license.
# The full text can be found in LICENSE in the root directory.

import inspect
import os
import random
import sys
import json
import hashlib
import time
import json
import traceback
from datetime import datetime

sys.path.insert(0, './zephyr/')
import zephyr_reporter

# Put this directory into the python path, so
# that devices may be imported.
import site
site.addsitedir(os.path.dirname(os.path.realpath(__file__)))

from devices import logstash, elasticlogger, get_device

import matplotlib
matplotlib.use('Agg')

def setup_dynamic_devices(config, env=None, start=None):
    '''Sets up dynamic devices from devices node in JSON config file'''

    config.devices = []
    for device in config.board['devices']:
        device['reboot'] = config.reboot_vms
        device['env'] = env
        device['lan_network'] = config.console.lan_network
        device['lan_gateway'] = config.console.lan_gateway
        device['start'] = start

        dyn_dev = get_device(device['type'], **device)
        if dyn_dev is not None:
            if 'name' not in device:
                raise Exception("Device in config is not named! This is required")
            setattr(config, device['name'], dyn_dev)
            config.devices.append(device['name'])

            # TODO: should this be here for should each device type set it?
            dyn_dev.start = start

            # TODO: set the following:
            #    reboot=config.reboot_vms,
            #    env=env,
            #    lan_network=config.console.lan_network,
            #    lan_gateway=config.console.lan_gateway,
            #    config=device)

            # if this device is a wan cmts provisioner, we set the device name
            # TODO: this should be generic
            if getattr(dyn_dev, 'wan_cmts_provisioner', False):
                setattr(config, 'provisioner', dyn_dev)
                config.devices.append('provisioner')

            continue

        print("Unknown device type for %s" % device)

def main():
    '''Connect to devices, run tests, record results.'''

    # Read command-line arguments
    import arguments
    config = arguments.parse()

    import library
    import devices
    from termcolor import colored
    from library import print_bold

    os.environ["TERM"] = "dumb"

    start = datetime.now()

    # Connect to any board in list
    connected_to_board = False
    random.shuffle(config.BOARD_NAMES)
    if config.features == []:
        # move boards with a feature to end of the list
        config.BOARD_NAMES = sorted(config.BOARD_NAMES, key=lambda x: 'feature' in config.boardfarm_config[x])
    for name in config.BOARD_NAMES:
        try:
            config.board = config.boardfarm_config[name]
        except Exception as e:
            print(e)
            print("Error reading info about board %s from board farm configuration." % name)
            break

        print_bold("Connecting to board named = %s, type = %s ..." % (name, config.board['board_type']))
        try:
            # None is legacy for tftp_server from before dynamic devices, leave it for now...
            tftp_server = None
            tftp_port = "22"

            uniqid = hashlib.md5("%0.100f" % time.time()).hexdigest()[:15]
            env = {"wan_iface": "wan%s" % uniqid[:12],
                    "lan_iface": "lan%s" % uniqid[:12],
                    "uniq_id": uniqid}


            # Connect to board
            config.console = devices.board_decider(config.board['board_type'],
                                                 conn_cmd=config.board['conn_cmd'],
                                                 power_ip=config.board.get('powerip', None),
                                                 power_outlet=config.board.get('powerport', None),
                                                 web_proxy=config.board.get('lan_device', None),
                                                 tftp_server=config.board.get('wan_device', tftp_server),
                                                 tftp_username=config.board.get('wan_username', 'root'),
                                                 tftp_password=config.board.get('wan_password', 'bigfoot1'),
                                                 tftp_port=config.board.get('wan_port', tftp_port),
                                                 connection_type=config.board.get('connection_type', None),
                                                 ssh_password=config.board.get('ssh_password', None),
                                                 power_username=config.board.get('power_username', None),
                                                 power_password=config.board.get('power_password', None),
                                                 rootfs=config.ROOTFS,
                                                 kernel=config.KERNEL,
                                                 config=config.board,
                                                 env=env,
                                                 start=start)
            print_bold("dut device console = %s" % colored("black", 'grey'))
            config.console.start = start

            if 'devices' in config.board:
                setup_dynamic_devices(config, env=env, start=start)

            def get_tftp_config(dev):
                saved = config.console.logfile_read
                config.console.logfile_read = None
                saved = dev.logfile_read
                dev.logfile_read = None
                if 'wan-no-eth0' in dev.kwargs.get('options', ""):
                    config.console.tftp_server = dev.get_interface_ipaddr("eth1")
                else:
                    config.console.tftp_server = dev.get_interface_ipaddr("eth0")
                dev.logfile_read = saved
                config.console.tftp_username = "root"
                config.console.tftp_password = "bigfoot1"
                config.console.tftp_port = "22"
                config.console.tftp_dev = dev
                config.console.logfile_read = saved

            # check devices after they start for tftpd-server option if
            # if we still have not configured a tftp server
            if tftp_server is None:
                for x in config.board['devices']:
                    if 'tftpd-server' in x.get('options', ""):
                        get_tftp_config(getattr(config, x['name']))
                        # TODO: how do we handle multiple tftp servers, break for now
                        break
            else:
                # check if the tftp_server is an unresolved name and resolve the ip
                for x in config.board['devices']:
                    if tftp_server == x.get('name', ""):
                        get_tftp_config(getattr(config, tftp_server))
                    # call for ip addr too since we want to fields populated
                    if tftp_server == x.get('ipaddr', ""):
                        config.console.tftp_dev = getattr(config, x.get('name'))

        except KeyboardInterrupt:
            print_bold("Keyboard interrupt")
            sys.exit(2)
        except Exception as e:
            print(e)
            traceback.print_exc(file=sys.stdout)
            connected_to_board = False
            continue
        connected_to_board = True
        break
    if not connected_to_board:
        print_bold("Failed to connect to any board")
        sys.exit(2)

    try:
        print_bold("Using Board %s, User %s" % (name, os.environ['BUILD_USER_ID']))
    except:
        print_bold("Using Board %s, User %s" % (name, os.environ['USER']))

    # Make devices (board, lan, wan, available to tests easily)
    devices.initialize_devices(config)

    # Write board info to json file and stdout
    config.board['station'] = name

    # Update config from board info
    if hasattr(config.console, "update_config"):
        config.console.update_config()

    print_bold('\n==========')
    library.print_board_info(config.board)

    # Run tests
    os.environ['TEST_START_TIME'] = datetime.now().strftime("%s")
    tests_to_run = []
    # Add tests from specified suite
    print_bold('==========\nTest suite "%s" has been specified, will attempt to run tests:' % config.TEST_SUITE)
    import tests
    tests.init(config)
    import testsuites
    if config.TEST_SUITE not in testsuites.list_tests:
        print_bold("Unable to find testsuite %s, aborting..." % config.TEST_SUITE)
        sys.exit(1)
    for i, name in enumerate(testsuites.list_tests[config.TEST_SUITE]):
        if isinstance(name, str):
            if not hasattr(tests, name):
                print_bold("\tTest %s skipped, not found..." % name)
                continue
            test = getattr(tests, name)
            test.start = start
        else:
            test = name
        print_bold("  %s %s from %s" % (i+1, test.__name__, inspect.getfile(test)))
        tests_to_run.append(test(config))
    if hasattr(config, 'EXTRA_TESTS') and config.EXTRA_TESTS:
        if tests_to_run[-1].__class__.__name__ == "Interact":
            print_bold("Last test is interact in testsuite, removing")
            tests_to_run.pop()

        print_bold("Extra tests specified on command line:")
        try:
            for name in config.EXTRA_TESTS:
                t = getattr(tests, name, None)
                if t is None:
                    raise Exception("Unable to load test from tests class!!!! Parsing of test selected via -e failed")
                print_bold("  %s" % t)
                test = t(config)
                test.start = start
                tests_to_run.append(test)
        except Exception as e:
            print_bold(e)
            print_bold("Unable to find specified extra tests, aborting...")
            sys.exit(1)

    print_bold('==========')
    try:
        tests_pass = tests_fail = tests_skip = 0
        curr_test = None
        for test in tests_to_run:
            curr_test = test
            test.run()
            curr_test = None
            grade = getattr(test, "result_grade", None)
            if grade == "OK" or grade == "Unexp OK":
                tests_pass += 1
            elif grade == "FAIL" or grade == "Exp FAIL":
                tests_fail += 1
            elif grade == "SKIP" or grade is None:
                tests_skip += 1

    except KeyboardInterrupt:
        print_bold("Run interrupted. Wrapping up...")
        if curr_test is not None:
            curr_test.recover()

    print_bold("Results run=%d failures=%d skipped=%d" % (tests_pass, tests_fail, tests_skip))

    try:
        config.console.close()
        if 'devices' in config.board:
            for device in config.devices:
                getattr(config, device).close()
        else:
            if config.lan is not None:
                config.lan.close()
            if config.wan is not None:
                config.wan.close()
    except Exception as e:
        print(e)
        print_bold("For some reason, could not close a connection.")
    library.print_board_info(config.board)

    combined_list = []
    def add_to_combined_list(log, name, combined_list=combined_list):
        for line in log.split('\r\n'):
            try:
                if line is '':
                    continue
                if line.startswith('\n'):
                    line = line[1:]
                if line.startswith(' ['):
                    line = line[1:]
                ts, text = line.split(']', 1)
                combined_list.append({"time": float(ts[1:-1]), "text": str(text), "name": name})
            except:
                print("Failed to parse log line = %s" % repr(line))
                pass

    idx = 1
    console_combined = []
    for console in config.console.consoles:
        with open(os.path.join(config.output_dir, 'console-%s.log' % idx), 'w') as clog:
            clog.write(console.log)
            add_to_combined_list(console.log, "console-%s" % idx)
            add_to_combined_list(console.log_calls, "console-%s" % idx)
            add_to_combined_list(console.log, "", console_combined)
        idx = idx + 1

    def write_combined_log(combined_list, fname):
        with open(os.path.join(config.output_dir, fname), 'w') as clog:
            for e in combined_list:
                try:
                    if e['name'] == "":
                        clog.write('[%s]%s\r\n' % (e['time'], e['text']))
                    else:
                        clog.write('%s: [%s] %s\n' % (e['name'], e['time'], e['text']))
                except:
                    print("failed to parse line: %s" % repr(e))

    import operator
    console_combined.sort(key=operator.itemgetter('time'))
    write_combined_log(console_combined, "console-combined.log")

    for device in config.devices:
        with open(os.path.join(config.output_dir, device + ".log"), 'w') as clog:
            d = getattr(config, device)
            if hasattr(d, 'log'):
                clog.write(d.log)
                add_to_combined_list(d.log, device)
                add_to_combined_list(d.log_calls, device)

    for test in tests_to_run:
        with open(os.path.join(config.output_dir, '%s.log' % test.__class__.__name__), 'w') as clog:
            if hasattr(test, 'log') and test.log != "":
                clog.write(test.log)
                add_to_combined_list(test.log, test.__class__.__name__)
            if hasattr(test, 'log_calls'):
                add_to_combined_list(test.log_calls, test.__class__.__name__)

    combined_list.sort(key=operator.itemgetter('time'))
    write_combined_log(combined_list, "all.log")

    os.environ['TEST_END_TIME'] = datetime.now().strftime("%s")

    # grab golden master results
    golden = {}
    if config.golden is not []:
        import requests
        for g in golden:
            try:
                golden.update(requests.get(config.golden).json())
            except:
                print_bold("Failed to fetch golden master results, skipping...")

    # Write test result messages to a file
    full_results = library.process_test_results(tests_to_run, golden)
    json.dump(full_results,
              open(os.path.join(config.output_dir + 'test_results.json'), 'w'),
              indent=4,
              sort_keys=True)

    # run all analysis classes (post processing)
    # also, never fail so we don't block automation
    try:
        import analysis
        for cstr in dir(analysis):
            c = getattr(analysis, cstr)
            if inspect.isclass(c) and issubclass(c, analysis.Analysis):
                with open(os.path.join(config.output_dir, "console-combined.log"), 'w') as clog:
                    c().analyze(clog, config.output_dir)
    except Exception as e:
        if not issubclass(type(e), (StopIteration)):
            print("Failed to run anaylsis:")
            print(e)

    # Try to remotely log information about this run
    info_for_remote_log = dict(config.board)
    info_for_remote_log.update(full_results)
    try:
        info_for_remote_log['duration'] = int(os.environ['TEST_END_TIME'])-int(os.environ['TEST_START_TIME'])
    except:
        pass
    if hasattr(config, 'TEST_SUITE'):
        info_for_remote_log['test_suite'] = str(config.TEST_SUITE)
    # logstash cannot handle multi-level json, remove full test results
    info_for_remote_log.pop('test_results', None)
    # but we will add back specific test results data
    for t in tests_to_run:
        def prepare_results_for_kibana(test, prefix=""):
            if hasattr(test, 'override_kibana_name'):
                n = test.override_kibana_name
            elif hasattr(test, 'name'):
                n = test.name
            else:
                n = test.__class__.__name__

            n = prefix + n

            for k, v in test.logged.items():
                info_for_remote_log[n + '-' + k] = v
            if hasattr(test, 'result_grade'):
                info_for_remote_log[n + "-result"] = test.result_grade

            return n

        prefix = prepare_results_for_kibana(t) + "-"
        for subtest in t.subtests:
            prepare_results_for_kibana(subtest, prefix=prefix)

    try:
        if config.logging_server is not None:
            logstash.RemoteLogger(config.logging_server).log(info_for_remote_log)
    except Exception as e:
        print(e)
        print("Unable to access logging_server specified in config. "
              "Results stored only locally.")

    try:
        if config.elasticsearch_server is not None:
            elasticlogger.ElasticsearchLogger(config.elasticsearch_server).log(info_for_remote_log)
        else:
            print("No elasticsearch_server specified in config. Results stored locally")
    except Exception as e:
        print(e)
        print("Unable to store results to elasticsearch_server specified in config. "
              "Results stored locally.")

    #Update the results in Zephyr
    print_bold('Starting Zephyr Execution....')

    try:
        result_data = json.load(open('./results/test_results.json'))
        length = len(result_data["test_results"])
        test_cases_list = []

        for tc in range(0, length):
            test_cases_list.append([])
            test_case = result_data["test_results"][tc]["name"]
            test_cases_list[tc].append(test_case)
            test_result = result_data["test_results"][tc]["grade"]
            test_cases_list[tc].append(test_result)

        zephyr_reporter.update_zephyr(test_cases_list)
    except Exception as e:
        print(e)
        print("Unable to Update results in Zephyr")

    # Create Pretty HTML output
    import make_human_readable
    try:
        title_str = make_human_readable.get_title()
        make_human_readable.xmlresults_to_html(full_results['test_results'], title=title_str,
                                output_name=os.path.join(config.output_dir, "results.html"),
                                board_info=config.board)
    except Exception as e:
        print(e)
        print("Unable to create HTML results")

    # Send url of pretty html results to MySQL build database
    try:
        library.send_results_to_myqsl(config.TEST_SUITE, config.output_dir)
    except Exception as e:
        print(e)
        print("Unable to log results to mysql database.")

    for t in tests_to_run:
        if t.log_to_file is not None and hasattr(t, 'stop_time'):
            filename = type(t).__name__ + '-' + time.strftime("%Y%m%d-%H%M%S") + ".txt"
            testtime = t.stop_time - t.start_time
            with open(os.path.join(config.output_dir, filename), 'w') as log:
                log.write('\t=======================================================')
                log.write('\n\tTest case ID: %s' % (type(t).__name__))
                log.write('\n\tTest case Description: %s' % (type(t).__doc__))
                log.write('\n\t=======================================================\n')
                log.write(t.log_to_file)
                log.write('\n\t=======================================================')
                log.write('\n\t%s test result: %s' % (type(t).__name__, t.result_grade))
                log.write('\n\tTotal test time: %s seconds' % testtime)
                log.write('\n\t=======================================================')
if __name__ == '__main__':
    main()
